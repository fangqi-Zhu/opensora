#!/usr/bin/env python3
# coding: utf-8


"""
Locate indices of webdataset_data_info items inside hdf5_data_info
and save the indices to a text file.
"""

from __future__ import annotations
import json
from collections import defaultdict
from pathlib import Path
from typing import List, Tuple, Dict


def load_json(path: str | Path) -> list:
    """Load a JSON file and return its root object."""
    with open(path, "r", encoding="utf-8") as fp:
        return json.load(fp)


def build_index_map(source: list) -> Dict[str, List[int]]:
    """
    Build a mapping from the JSON-serialized form of each element to
    all indices where that element appears in *source*.

    We JSON-dump with sort_keys=True so that key order doesnâ€™t affect equality.
    """
    index_map: Dict[str, List[int]] = defaultdict(list)
    for idx, item in enumerate(source):
        key = json.dumps(item, ensure_ascii=False, sort_keys=True)
        index_map[key].append(idx)
    return index_map


def lookup_indices(source_map: Dict[str, List[int]], targets: list) -> Tuple[List[int], List[int]]:
    """
    For every *targets* element, fetch the first index recorded in *source_map*.
    Returns (found_indices, missing_count).
    """
    found: List[int] = []
    missing: List[int] = []

    for item in targets:
        key = json.dumps(item, ensure_ascii=False, sort_keys=True)
        if key in source_map:
            found.append(source_map[key][0])  # å–ç¬¬ä¸€æ¬¡å‡ºç°çš„ä½ç½®
        else:
            missing.append(item)

    return found, missing


def main() -> None:
    # -------- è·¯å¾„è®¾ç½® --------
    hdf5_path = Path("/opt/tiger/opensora/hdf5_data_info.json")
    web_path = Path("/opt/tiger/opensora/sampled_rollout_batches_meta.json")
    out_path = Path("web_in_hdf5_indices.txt")

    # -------- æ•°æ®è½½å…¥ --------
    hdf5_data = load_json(hdf5_path)
    web_data = load_json(web_path) # å¦‚éœ€å…¨éƒ¨æ•°æ®ï¼Œåˆ é™¤åˆ‡ç‰‡

    # -------- ç”Ÿæˆç´¢å¼• --------
    index_map = build_index_map(hdf5_data)
    indices, missing = lookup_indices(index_map, web_data)
    print(len(set(indices)))
    print(len(indices)) # , "æœ‰é‡å¤çš„ç´¢å¼•"

    # -------- å†™å…¥æ–‡ä»¶ --------
    out_path.write_text("\n".join(map(str, indices)), encoding="utf-8")
    print(f"âœ… å·²å†™å…¥ {len(indices)} ä¸ªç´¢å¼•åˆ° {out_path.resolve()}")

    # -------- ç»“æœæ£€æŸ¥ --------
    if missing:
        print(f"âš ï¸  æœ‰ {len(missing)} ä¸ªå…ƒç´ åœ¨ hdf5_data_info.json ä¸­æœªæ‰¾åˆ°ã€‚")
    else:
        print("ğŸ‰ webdataset_first_buffer ä¸­çš„æ‰€æœ‰å…ƒç´ å‡å‡ºç°åœ¨ hdf5_data_info.json ä¸­ã€‚")


if __name__ == "__main__":
    main()
